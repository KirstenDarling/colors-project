{"version":3,"file":"index.mjs","sources":["../src/listen.ts","../src/drafts.ts","../src/patch.ts","../src/syncingDataset.ts","../src/groqStore.ts","../src/exportUtils.ts","../src/node/getDocuments.ts","../src/node/support.ts","../src/index.ts"],"sourcesContent":["import {Subscription, MutationEvent, Config, ApiError, EnvImplementations} from './types'\nimport type BrowserEventSource from '@sanity/eventsource/browser'\nimport type NodeEventSource from '@sanity/eventsource/node'\n\ntype EventSourceInstance = InstanceType<EnvImplementations['EventSource']>\n\n// The events used by Content Lake: https://www.sanity.io/docs/listening\nexport interface SharedEventSourceEventMap {\n  welcome: MessageEvent\n  mutation: MessageEvent\n  channelError: MessageEvent\n  disconnect: MessageEvent\n  error: Event\n}\ndeclare module 'event-source-polyfill' {\n  export interface EventSourceEventMap extends SharedEventSourceEventMap {}\n}\n\nconst isNativeBrowserEventSource = (\n  eventSource: EventSourceInstance\n): eventSource is InstanceType<typeof globalThis.EventSource> =>\n  typeof window !== 'undefined' &&\n  eventSource.addEventListener === window.EventSource.prototype.addEventListener\n\nconst isPolyfillEventSource = (\n  eventSource: EventSourceInstance\n): eventSource is InstanceType<typeof BrowserEventSource | typeof NodeEventSource> =>\n  !isNativeBrowserEventSource(eventSource)\n\nconst addEventSourceListener = (\n  eventSource: EventSourceInstance,\n  type: keyof SharedEventSourceEventMap,\n  listener: EventListener\n): void => {\n  if (isPolyfillEventSource(eventSource)) {\n    // Polyfilled event source does not accept option parameter\n    eventSource.addEventListener(type, listener as any)\n  } else {\n    eventSource.addEventListener(type, listener, false)\n  }\n}\n\nexport function listen(\n  EventSourceImpl: EnvImplementations['EventSource'],\n  config: Config,\n  handlers: {\n    open: () => void\n    error: (err: Error) => void\n    next: (event: MutationEvent) => void\n  }\n): Subscription {\n  const {projectId, dataset, token} = config\n  const headers = token ? {Authorization: `Bearer ${token}`} : undefined\n  const url = `https://${projectId}.api.sanity.io/v1/data/listen/${dataset}?query=*&effectFormat=mendoza`\n  const es = new EventSourceImpl(url, {withCredentials: true, headers})\n\n  addEventSourceListener(es, 'welcome', handlers.open)\n\n  addEventSourceListener(es, 'mutation', getMutationParser(handlers.next))\n\n  addEventSourceListener(es, 'channelError', (msg: any) => {\n    es.close()\n\n    let data\n    try {\n      data = JSON.parse(msg.data) as ApiError\n    } catch (err) {\n      handlers.error(new Error('Unknown error parsing listener message'))\n      return\n    }\n\n    handlers.error(\n      new Error(data.message || data.error || `Listener returned HTTP ${data.statusCode}`)\n    )\n  })\n\n  addEventSourceListener(es, 'error', (err: Event) => {\n    const origin = typeof window !== 'undefined' && window.location.origin\n    const hintSuffix = origin ? `, and that the CORS-origin (${origin}) is allowed` : ''\n    const errorMessage = isErrorLike(err) ? ` (${err.message})` : ''\n    handlers.error(\n      new Error(\n        `Error establishing listener - check that the project ID and dataset are correct${hintSuffix}${errorMessage}`\n      )\n    )\n  })\n\n  return {\n    unsubscribe: (): Promise<void> => Promise.resolve(es.close()),\n  }\n}\n\nfunction getMutationParser(cb: (event: MutationEvent) => void): (msg: any) => void {\n  return (msg: any) => {\n    let data\n    try {\n      data = JSON.parse(msg.data)\n    } catch (err) {\n      // intentional noop\n      return\n    }\n\n    cb(data)\n  }\n}\n\nfunction isErrorLike(err: unknown): err is {message: string} {\n  return typeof err === 'object' && err !== null && 'message' in err\n}\n","import {SanityDocument} from '@sanity/types'\n\nexport function isDraft(doc: SanityDocument): boolean {\n  return doc._id.startsWith('drafts.')\n}\n\nexport function getPublishedId(document: SanityDocument): string {\n  return isDraft(document) ? document._id.slice(7) : document._id\n}\n","import {SanityDocument} from '@sanity/types'\nimport {applyPatch} from 'mendoza'\n\nexport function applyPatchWithoutRev(\n  doc: SanityDocument | null,\n  patch: unknown[]\n): SanityDocument | null {\n  const patchDoc = {...doc} as Omit<SanityDocument, '_rev'>\n  delete patchDoc._rev\n  return applyPatch(patchDoc, patch)\n}\n","import {SanityDocument} from '@sanity/types'\nimport {listen} from './listen'\nimport {getPublishedId} from './drafts'\nimport {applyPatchWithoutRev} from './patch'\nimport {Config, EnvImplementations, MutationEvent, Subscription} from './types'\n\nconst DEBOUNCE_MS = 25\n\nfunction noop() {\n  return Promise.resolve()\n}\n\nexport function getSyncingDataset(\n  config: Config,\n  onNotifyUpdate: (docs: SanityDocument[]) => void,\n  {getDocuments, EventSource}: EnvImplementations\n): Subscription & {loaded: Promise<void>} {\n  const {\n    projectId,\n    dataset,\n    listen: useListener,\n    overlayDrafts,\n    documentLimit,\n    token,\n    includeTypes,\n  } = config\n\n  // We don't want to flush updates while we're in the same transaction, so a normal\n  // throttle/debounce wouldn't do it. We need to wait and see if the next mutation is\n  // within the same transaction as the previous, and if not we can flush. Of course,\n  // we can't wait forever, so an upper threshold of X ms should be counted as \"ok to flush\"\n  let stagedDocs: SanityDocument[] | undefined\n  let previousTrx: string | undefined\n  let flushTimeout: NodeJS.Timer | undefined\n\n  const onUpdate = (docs: SanityDocument[]) => {\n    stagedDocs = undefined\n    flushTimeout = undefined\n    previousTrx = undefined\n    onNotifyUpdate(overlayDrafts ? overlay(docs) : docs)\n  }\n\n  if (!useListener) {\n    const loaded = getDocuments({projectId, dataset, documentLimit, token, includeTypes})\n      .then(onUpdate)\n      .then(noop)\n    return {unsubscribe: noop, loaded}\n  }\n\n  const indexedDocuments = new Map<string, SanityDocument>()\n\n  // undefined until the listener has been set up and the initial export is done\n  let documents: SanityDocument[] | undefined\n\n  // holds any mutations that happen while fetching documents so they can be applied after updates\n  const buffer: MutationEvent[] = []\n\n  // Return a promise we can resolve once we've established a listener and reconciled any mutations\n  let onDoneLoading: () => void\n  let onLoadError: (error: Error) => void\n  const loaded = new Promise<void>((resolve, reject) => {\n    onDoneLoading = resolve\n    onLoadError = reject\n  })\n\n  const onOpen = async () => {\n    const initial = await getDocuments({projectId, dataset, documentLimit, token, includeTypes})\n    documents = applyBufferedMutations(initial, buffer)\n    documents.forEach((doc) => indexedDocuments.set(doc._id, doc))\n    onUpdate(documents)\n    onDoneLoading()\n  }\n\n  const onMutationReceived = (msg: MutationEvent) => {\n    if (documents) {\n      applyMutation(msg)\n      scheduleUpdate(documents, msg)\n    } else {\n      buffer.push(msg)\n    }\n  }\n\n  const listener = listen(EventSource, config, {\n    next: onMutationReceived,\n    open: onOpen,\n    error: (error: Error) => onLoadError(error),\n  })\n\n  const scheduleUpdate = (docs: SanityDocument[], msg: MutationEvent) => {\n    clearTimeout(flushTimeout)\n\n    if (previousTrx !== msg.transactionId && stagedDocs) {\n      // This is a new transaction, meaning we can immediately flush any pending\n      // doc updates if there are any\n      onUpdate(stagedDocs)\n      previousTrx = undefined\n    } else {\n      previousTrx = msg.transactionId\n      stagedDocs = docs.slice()\n    }\n\n    flushTimeout = setTimeout(onUpdate, DEBOUNCE_MS, docs.slice())\n  }\n\n  const applyMutation = (msg: MutationEvent) => {\n    if (!msg.effects || msg.documentId.startsWith('_.')) {\n      return\n    }\n\n    const document = indexedDocuments.get(msg.documentId) || null\n    replaceDocument(msg.documentId, applyPatchWithoutRev(document, msg.effects.apply))\n  }\n\n  const replaceDocument = (id: string, document: SanityDocument | null) => {\n    const current = indexedDocuments.get(id)\n    const docs = documents || []\n    const position = current ? docs.indexOf(current) : -1\n\n    if (position === -1 && document) {\n      // Didn't exist previously, but was now created. Add it.\n      docs.push(document)\n      indexedDocuments.set(id, document)\n    } else if (document) {\n      // Existed previously and still does. Replace it.\n      docs.splice(position, 1, document)\n      indexedDocuments.set(id, document)\n    } else {\n      // Existed previously, but is now deleted. Remove it.\n      docs.splice(position, 1)\n      indexedDocuments.delete(id)\n    }\n  }\n\n  return {unsubscribe: listener.unsubscribe, loaded}\n}\n\nfunction applyBufferedMutations(\n  documents: SanityDocument[],\n  mutations: MutationEvent[]\n): SanityDocument[] {\n  // Group by document ID\n  const groups = new Map<string, MutationEvent[]>()\n  mutations.forEach((mutation) => {\n    const group = groups.get(mutation.documentId) || []\n    group.push(mutation)\n    groups.set(mutation.documentId, group)\n  })\n\n  // Discard all mutations that happened before our current document\n  groups.forEach((group, id) => {\n    const document = documents.find((doc) => doc._id === id)\n    if (!document) {\n      // @todo handle\n      // eslint-disable-next-line no-console\n      console.warn('Received mutation for missing document %s', id)\n      return\n    }\n\n    // Mutations are sorted by timestamp, apply any that arrived after\n    // we fetched the initial documents\n    let hasFoundRevision = false\n    let current: SanityDocument | null = document\n    group.forEach((mutation) => {\n      hasFoundRevision = hasFoundRevision || mutation.previousRev === document._rev\n      if (!hasFoundRevision) {\n        return\n      }\n\n      if (mutation.effects) {\n        current = applyPatchWithoutRev(current, mutation.effects.apply)\n      }\n    })\n\n    // Replace the indexed documents\n    documents.splice(documents.indexOf(document), 1, current)\n  })\n\n  return documents\n}\n\nfunction overlay(documents: SanityDocument[]): SanityDocument[] {\n  const overlayed = new Map<string, SanityDocument>()\n\n  documents.forEach((doc) => {\n    const existing = overlayed.get(getPublishedId(doc))\n    if (doc._id.startsWith('drafts.')) {\n      // Drafts always overlay\n      overlayed.set(getPublishedId(doc), pretendThatItsPublished(doc))\n    } else if (!existing) {\n      // Published documents only override if draft doesn't exist\n      overlayed.set(doc._id, doc)\n    }\n  })\n\n  return Array.from(overlayed.values())\n}\n\n// Strictly speaking it would be better to allow groq-js to resolve `draft.<id>`,\n// but for now this will have to do\nfunction pretendThatItsPublished(doc: SanityDocument): SanityDocument {\n  return {...doc, _id: getPublishedId(doc)}\n}\n","import groq from 'groq'\nimport deepEqual from 'fast-deep-equal'\nimport {throttle} from 'throttle-debounce'\nimport {SanityDocument} from '@sanity/types'\nimport {parse, evaluate} from 'groq-js'\nimport {Config, EnvImplementations, GroqSubscription, GroqStore, Subscription} from './types'\nimport {getSyncingDataset} from './syncingDataset'\n\nexport function groqStore(config: Config, envImplementations: EnvImplementations): GroqStore {\n  let documents: SanityDocument[] = []\n  const executeThrottled = throttle(config.subscriptionThrottleMs || 50, executeAllSubscriptions)\n  const activeSubscriptions: GroqSubscription[] = []\n\n  let dataset: Subscription & {loaded: Promise<void>}\n\n  async function loadDataset() {\n    if (!dataset) {\n      dataset = getSyncingDataset(\n        config,\n        (docs) => {\n          documents = docs\n          executeThrottled()\n        },\n        envImplementations\n      )\n    }\n\n    await dataset.loaded\n  }\n\n  async function query<R = any>(groqQuery: string, params?: Record<string, unknown>): Promise<R> {\n    await loadDataset()\n    const tree = parse(groqQuery, {params})\n    const result = await evaluate(tree as any, {dataset: documents, params})\n    return result.get()\n  }\n\n  async function getDocument(documentId: string): Promise<SanityDocument | null> {\n    await loadDataset()\n    return query(groq`*[_id == $id][0]`, {id: documentId})\n  }\n\n  async function getDocuments(documentIds: string[]): Promise<(SanityDocument | null)[]> {\n    await loadDataset()\n    const subQueries = documentIds.map((id) => `*[_id == \"${id}\"][0]`).join(',\\n')\n    return query(`[${subQueries}]`)\n  }\n\n  function subscribe<R = any>(\n    groqQuery: string,\n    params: Record<string, unknown>,\n    callback: (error: Error | undefined, result?: R) => void\n  ): Subscription {\n    if (!config.listen) {\n      throw new Error('Cannot use `subscribe()` without `listen: true`')\n    }\n\n    // @todo Execute the query against an empty dataset for validation purposes\n\n    // Store the subscription so we can re-run the query on new data\n    const subscription = {query: groqQuery, params, callback}\n    activeSubscriptions.push(subscription)\n\n    let unsubscribed = false\n    const unsubscribe = () => {\n      if (unsubscribed) {\n        return Promise.resolve()\n      }\n\n      unsubscribed = true\n      activeSubscriptions.splice(activeSubscriptions.indexOf(subscription), 1)\n      return Promise.resolve()\n    }\n\n    executeQuerySubscription(subscription)\n    return {unsubscribe}\n  }\n\n  function executeQuerySubscription(subscription: GroqSubscription) {\n    return query(subscription.query, subscription.params)\n      .then((res) => {\n        if ('previousResult' in subscription && deepEqual(subscription.previousResult, res)) {\n          return\n        }\n\n        subscription.previousResult = res\n        subscription.callback(undefined, res)\n      })\n      .catch((err) => {\n        subscription.callback(err)\n      })\n  }\n\n  function executeAllSubscriptions() {\n    activeSubscriptions.forEach(executeQuerySubscription)\n  }\n\n  function close() {\n    executeThrottled.cancel()\n    return dataset ? dataset.unsubscribe() : Promise.resolve()\n  }\n\n  return {query, getDocument, getDocuments, subscribe, close}\n}\n","import {SanityDocument} from '@sanity/types'\nimport {ApiError, StreamError, StreamResult} from './types'\n\nexport function isStreamError(result: StreamResult | undefined): result is StreamError {\n  if (!result) {\n    return false\n  }\n\n  if (!('error' in result) || typeof result.error !== 'object' || result.error === null) {\n    return false\n  }\n\n  return (\n    'description' in result.error &&\n    typeof (result as StreamError).error.description === 'string' &&\n    !('_id' in result)\n  )\n}\n\nexport function getError(body: ApiError): string {\n  if (typeof body === 'object' && 'error' in body && 'message' in body) {\n    return body.message || body.error\n  }\n\n  return '<unknown error>'\n}\n\nexport function isRelevantDocument(doc: SanityDocument): boolean {\n  return !doc._id.startsWith('_.')\n}\n","import split from 'split2'\nimport get from 'simple-get'\nimport {SanityDocument} from '@sanity/types'\nimport {EnvImplementations, StreamResult} from '../types'\nimport {getError, isRelevantDocument, isStreamError} from '../exportUtils'\n\nexport const getDocuments: EnvImplementations['getDocuments'] = function getDocuments({\n  projectId,\n  dataset,\n  token,\n  documentLimit,\n  includeTypes = [],\n}: {\n  projectId: string\n  dataset: string\n  token?: string\n  documentLimit?: number\n  includeTypes?: string[]\n}): Promise<SanityDocument[]> {\n  const baseUrl = `https://${projectId}.api.sanity.io/v1/data/export/${dataset}`\n  const params =\n    includeTypes.length > 0 ? new URLSearchParams({types: includeTypes?.join(',')}) : ''\n  const url = `${baseUrl}?${params}`\n  const headers = token ? {Authorization: `Bearer ${token}`} : undefined\n\n  return new Promise((resolve, reject) => {\n    get({url, headers}, (err, response) => {\n      if (err) {\n        reject(err)\n        return\n      }\n\n      response.setEncoding('utf8')\n\n      const chunks: Buffer[] = []\n      if (response.statusCode !== 200) {\n        response\n          .on('data', (chunk: Buffer) => chunks.push(chunk))\n          .on('end', () => {\n            const body = JSON.parse(Buffer.concat(chunks).toString('utf8'))\n            reject(new Error(`Error streaming dataset: ${getError(body)}`))\n          })\n        return\n      }\n\n      const documents: SanityDocument[] = []\n      response\n        .pipe(split(JSON.parse))\n        .on('data', (doc: StreamResult) => {\n          if (isStreamError(doc)) {\n            reject(new Error(`Error streaming dataset: ${doc.error}`))\n            return\n          }\n\n          if (doc && isRelevantDocument(doc)) {\n            documents.push(doc)\n          }\n\n          if (documentLimit && documents.length > documentLimit) {\n            reject(\n              new Error(`Error streaming dataset: Reached limit of ${documentLimit} documents`)\n            )\n            response.destroy()\n          }\n        })\n        .on('end', () => resolve(documents))\n    })\n  })\n}\n","export function assertEnvSupport(): void {\n  const [major] = process.version.replace(/^v/, '').split('.', 1).map(Number)\n  if (major < 14) {\n    throw new Error('Node.js version 14 or higher required')\n  }\n}\n","/**\n * Note: Entry point for _browser_ build is in browser/index.ts\n */\nimport EventSourcePolyfill from '@sanity/eventsource/node'\nimport {groqStore as groqStoreApi} from './groqStore'\nimport {Config, GroqStore} from './types'\nimport {getDocuments} from './node/getDocuments'\nimport {assertEnvSupport} from './node/support'\n\n/** @public */\nexport function groqStore(config: Config): GroqStore {\n  assertEnvSupport()\n\n  return groqStoreApi(config, {\n    EventSource: config.EventSource ?? EventSourcePolyfill,\n    getDocuments,\n  })\n}\n\nexport {default as groq} from 'groq'\nexport type {Subscription, GroqStore, Config, EnvImplementations} from './types'\n"],"names":["isNativeBrowserEventSource","eventSource","window","addEventListener","EventSource","prototype","isPolyfillEventSource","addEventSourceListener","type","listener","listen","EventSourceImpl","config","handlers","projectId","dataset","token","headers","Authorization","concat","url","es","withCredentials","open","getMutationParser","next","msg","close","data","JSON","parse","err","error","Error","message","statusCode","origin","location","hintSuffix","errorMessage","isErrorLike","unsubscribe","Promise","resolve","cb","isDraft","doc","_id","startsWith","getPublishedId","document","slice","applyPatchWithoutRev","patch","patchDoc","_rev","applyPatch","DEBOUNCE_MS","noop","getSyncingDataset","onNotifyUpdate","_ref","getDocuments","useListener","overlayDrafts","documentLimit","includeTypes","stagedDocs","previousTrx","flushTimeout","onUpdate","docs","overlay","loaded","then","indexedDocuments","Map","documents","buffer","onDoneLoading","onLoadError","reject","onOpen","initial","applyBufferedMutations","forEach","set","onMutationReceived","applyMutation","scheduleUpdate","push","clearTimeout","transactionId","setTimeout","effects","documentId","get","replaceDocument","apply","id","current","position","indexOf","splice","delete","mutations","groups","mutation","group","find","console","warn","hasFoundRevision","previousRev","overlayed","existing","pretendThatItsPublished","Array","from","values","groqStore","groqStore$1","envImplementations","executeThrottled","throttle","subscriptionThrottleMs","executeAllSubscriptions","activeSubscriptions","loadDataset","query","groqQuery","params","tree","result","evaluate","getDocument","groq","_templateObject","_taggedTemplateLiteral","documentIds","subQueries","map","join","subscribe","callback","subscription","unsubscribed","executeQuerySubscription","res","deepEqual","previousResult","catch","cancel","isStreamError","description","getError","body","isRelevantDocument","getDocuments2","_ref2","baseUrl","length","URLSearchParams","types","response","setEncoding","chunks","on","chunk","Buffer","toString","pipe","split","destroy","assertEnvSupport","major","process","version","replace","Number","_a","groqStoreApi","EventSourcePolyfill"],"mappings":";;;;;;;;;;;AAkBA,MAAMA,0BAAA,GACJC,WAAA,IAEA,OAAOC,MAAA,KAAW,eAClBD,WAAY,CAAAE,gBAAA,KAAqBD,MAAO,CAAAE,WAAA,CAAYC,SAAU,CAAAF,gBAAA;AAEhE,MAAMG,qBAAwB,GAC5BL,WAEA,IAAA,CAACD,2BAA2BC,WAAW,CAAA;AAEzC,MAAMM,sBAAyB,GAAAA,CAC7BN,WACA,EAAAO,IAAA,EACAC,QACS,KAAA;EACL,IAAAH,qBAAA,CAAsBL,WAAW,CAAG,EAAA;IAE1BA,WAAA,CAAAE,gBAAA,CAAiBK,MAAMC,QAAe,CAAA;EAAA,CAC7C,MAAA;IACOR,WAAA,CAAAE,gBAAA,CAAiBK,IAAM,EAAAC,QAAA,EAAU,KAAK,CAAA;EACpD;AACF,CAAA;AAEgB,SAAAC,MAAAA,CACdC,eACA,EAAAC,MAAA,EACAC,QAKc,EAAA;EACd,MAAM;IAACC,SAAA;IAAWC,OAAS;IAAAC;EAAA,CAAS,GAAAJ,MAAA;EACpC,MAAMK,UAAUD,KAAQ,GAAA;IAACE,aAAe,YAAAC,MAAA,CAAUH;GAAW,GAAA,KAAA,CAAA;EACvD,MAAAI,GAAA,cAAAD,MAAA,CAAiBL,SAA0C,oCAAAK,MAAA,CAAAJ,OAAA,kCAAA;EAC3D,MAAAM,EAAA,GAAK,IAAIV,eAAgB,CAAAS,GAAA,EAAK;IAACE,eAAiB,EAAA,IAAA;IAAML;GAAQ,CAAA;EAE7CV,sBAAA,CAAAc,EAAA,EAAI,SAAW,EAAAR,QAAA,CAASU,IAAI,CAAA;EAEnDhB,sBAAA,CAAuBc,EAAI,EAAA,UAAA,EAAYG,iBAAkB,CAAAX,QAAA,CAASY,IAAI,CAAC,CAAA;EAEhDlB,sBAAA,CAAAc,EAAA,EAAI,cAAgB,EAACK,GAAa,IAAA;IACvDL,EAAA,CAAGM,KAAM,EAAA;IAEL,IAAAC,IAAA;IACA,IAAA;MACKA,IAAA,GAAAC,IAAA,CAAKC,KAAM,CAAAJ,GAAA,CAAIE,IAAI,CAAA;aACnBG,GAAP,EAAA;MACAlB,QAAA,CAASmB,KAAM,CAAA,IAAIC,KAAM,CAAA,wCAAwC,CAAC,CAAA;MAClE;IACF;IAESpB,QAAA,CAAAmB,KAAA,CACP,IAAIC,MAAML,IAAK,CAAAM,OAAA,IAAWN,KAAKI,KAAS,8BAAAb,MAAA,CAA0BS,KAAKO,UAAY,CAAA,CAAA,CACrF;EAAA,CACD,CAAA;EAEsB5B,sBAAA,CAAAc,EAAA,EAAI,OAAS,EAACU,GAAe,IAAA;IAClD,MAAMK,MAAS,GAAA,OAAOlC,MAAW,KAAA,WAAA,IAAeA,OAAOmC,QAAS,CAAAD,MAAA;IAC1D,MAAAE,UAAA,GAAaF,MAAS,kCAAAjB,MAAA,CAA+BiB,MAAuB,oBAAA,EAAA;IAClF,MAAMG,eAAeC,WAAY,CAAAT,GAAG,CAAI,QAAAZ,MAAA,CAAKY,IAAIG,OAAa,SAAA,EAAA;IACrDrB,QAAA,CAAAmB,KAAA,CACP,IAAIC,KAAA,mFAAAd,MAAA,CACgFmB,UAAa,EAAAnB,MAAA,CAAAoB,YAAA,EACjG,CACF;EAAA,CACD,CAAA;EAEM,OAAA;IACLE,aAAaA,CAAA,KAAqBC,OAAA,CAAQC,OAAQ,CAAAtB,EAAA,CAAGM,OAAO;EAAA,CAC9D;AACF;AAEA,SAASH,kBAAkBoB,EAAwD,EAAA;EACjF,OAAQlB,GAAa,IAAA;IACf,IAAAE,IAAA;IACA,IAAA;MACKA,IAAA,GAAAC,IAAA,CAAKC,KAAM,CAAAJ,GAAA,CAAIE,IAAI,CAAA;aACnBG,GAAP,EAAA;MAEA;IACF;IAEAa,EAAA,CAAGhB,IAAI,CAAA;EAAA,CACT;AACF;AAEA,SAASY,YAAYT,GAAwC,EAAA;EAC3D,OAAO,OAAOA,GAAA,KAAQ,QAAY,IAAAA,GAAA,KAAQ,QAAQ,SAAa,IAAAA,GAAA;AACjE;AC1GO,SAASc,QAAQC,GAA8B,EAAA;EAC7C,OAAAA,GAAA,CAAIC,GAAI,CAAAC,UAAA,CAAW,SAAS,CAAA;AACrC;AAEO,SAASC,eAAeC,QAAkC,EAAA;EACxD,OAAAL,OAAA,CAAQK,QAAQ,CAAI,GAAAA,QAAA,CAASH,IAAII,KAAM,CAAA,CAAC,IAAID,QAAS,CAAAH,GAAA;AAC9D;ACLgB,SAAAK,oBAAAA,CACdN,KACAO,KACuB,EAAA;EACjB,MAAAC,QAAA,GAAW;IAAC,GAAGR;GAAG;EACxB,OAAOQ,QAAS,CAAAC,IAAA;EACT,OAAAC,UAAA,CAAWF,UAAUD,KAAK,CAAA;AACnC;ACJA,MAAMI,WAAc,GAAA,EAAA;AAEpB,SAASC,IAAOA,CAAA,EAAA;EACd,OAAOhB,QAAQC,OAAQ,EAAA;AACzB;AAEO,SAASgB,kBACd/C,MACA,EAAAgD,cAAA,EAAAC,IAAA,EAEwC;EAAA,IADxC;IAACC,YAAA;IAAc1D;GACyB,GAAAyD,IAAA;EAClC,MAAA;IACJ/C,SAAA;IACAC,OAAA;IACAL,MAAQ,EAAAqD,WAAA;IACRC,aAAA;IACAC,aAAA;IACAjD,KAAA;IACAkD;EACE,CAAA,GAAAtD,MAAA;EAMA,IAAAuD,UAAA;EACA,IAAAC,WAAA;EACA,IAAAC,YAAA;EAEE,MAAAC,QAAA,GAAYC,IAA2B,IAAA;IAC9BJ,UAAA,GAAA,KAAA,CAAA;IACEE,YAAA,GAAA,KAAA,CAAA;IACDD,WAAA,GAAA,KAAA,CAAA;IACdR,cAAA,CAAeI,aAAgB,GAAAQ,OAAA,CAAQD,IAAI,CAAA,GAAIA,IAAI,CAAA;EAAA,CACrD;EAEA,IAAI,CAACR,WAAa,EAAA;IAChB,MAAMU,OAAS,GAAAX,YAAA,CAAa;MAAChD,SAAA;MAAWC;MAASkD,aAAe;MAAAjD,KAAA;MAAOkD;IAAa,CAAA,CACjF,CAAAQ,IAAA,CAAKJ,QAAQ,CAAA,CACbI,KAAKhB,IAAI,CAAA;IACZ,OAAO;MAACjB,WAAA,EAAaiB,IAAM;MAAAe,MAAA,EAAAA;IAAM,CAAA;EACnC;EAEM,MAAAE,gBAAA,GAAA,mBAAuBC,GAA4B,EAAA;EAGrD,IAAAC,SAAA;EAGJ,MAAMC,SAA0B,EAAC;EAG7B,IAAAC,aAAA;EACA,IAAAC,WAAA;EACJ,MAAMP,MAAS,GAAA,IAAI/B,OAAc,CAAA,CAACC,SAASsC,MAAW,KAAA;IACpCF,aAAA,GAAApC,OAAA;IACFqC,WAAA,GAAAC,MAAA;EAAA,CACf,CAAA;EAED,MAAMC,SAAS,MAAAA,CAAA,KAAY;IACnB,MAAAC,OAAA,GAAU,MAAMrB,YAAa,CAAA;MAAChD;MAAWC,OAAS;MAAAkD,aAAA;MAAejD,KAAO;MAAAkD;IAAA,CAAa,CAAA;IAC/EW,SAAA,GAAAO,sBAAA,CAAuBD,SAASL,MAAM,CAAA;IACxCD,SAAA,CAAAQ,OAAA,CAASvC,GAAQ,IAAA6B,gBAAA,CAAiBW,IAAIxC,GAAI,CAAAC,GAAA,EAAKD,GAAG,CAAC,CAAA;IAC7DwB,QAAA,CAASO,SAAS,CAAA;IACJE,aAAA,EAAA;EAAA,CAChB;EAEM,MAAAQ,kBAAA,GAAsB7D,GAAuB,IAAA;IACjD,IAAImD,SAAW,EAAA;MACbW,aAAA,CAAc9D,GAAG,CAAA;MACjB+D,cAAA,CAAeZ,WAAWnD,GAAG,CAAA;IAAA,CACxB,MAAA;MACLoD,MAAA,CAAOY,KAAKhE,GAAG,CAAA;IACjB;EAAA,CACF;EAEM,MAAAjB,QAAA,GAAWC,MAAO,CAAAN,WAAA,EAAaQ,MAAQ,EAAA;IAC3Ca,IAAM,EAAA8D,kBAAA;IACNhE,IAAM,EAAA2D,MAAA;IACNlD,KAAO,EAACA,KAAiB,IAAAgD,WAAA,CAAYhD,KAAK;EAAA,CAC3C,CAAA;EAEK,MAAAyD,cAAA,GAAiBA,CAAClB,IAAA,EAAwB7C,GAAuB,KAAA;IACrEiE,YAAA,CAAatB,YAAY,CAAA;IAErB,IAAAD,WAAA,KAAgB1C,GAAI,CAAAkE,aAAA,IAAiBzB,UAAY,EAAA;MAGnDG,QAAA,CAASH,UAAU,CAAA;MACLC,WAAA,GAAA,KAAA,CAAA;IAAA,CACT,MAAA;MACLA,WAAA,GAAc1C,GAAI,CAAAkE,aAAA;MAClBzB,UAAA,GAAaI,KAAKpB,KAAM,EAAA;IAC1B;IAEAkB,YAAA,GAAewB,UAAW,CAAAvB,QAAA,EAAUb,WAAa,EAAAc,IAAA,CAAKpB,OAAO,CAAA;EAAA,CAC/D;EAEM,MAAAqC,aAAA,GAAiB9D,GAAuB,IAAA;IAC5C,IAAI,CAACA,GAAI,CAAAoE,OAAA,IAAWpE,IAAIqE,UAAW,CAAA/C,UAAA,CAAW,IAAI,CAAG,EAAA;MACnD;IACF;IAEA,MAAME,QAAW,GAAAyB,gBAAA,CAAiBqB,GAAI,CAAAtE,GAAA,CAAIqE,UAAU,CAAK,IAAA,IAAA;IACzDE,eAAA,CAAgBvE,IAAIqE,UAAY,EAAA3C,oBAAA,CAAqBF,UAAUxB,GAAI,CAAAoE,OAAA,CAAQI,KAAK,CAAC,CAAA;EAAA,CACnF;EAEM,MAAAD,eAAA,GAAkBA,CAACE,EAAA,EAAYjD,QAAoC,KAAA;IACjE,MAAAkD,OAAA,GAAUzB,gBAAiB,CAAAqB,GAAA,CAAIG,EAAE,CAAA;IACjC,MAAA5B,IAAA,GAAOM,aAAa,EAAC;IAC3B,MAAMwB,QAAW,GAAAD,OAAA,GAAU7B,IAAK,CAAA+B,OAAA,CAAQF,OAAO,CAAI,GAAA,CAAA,CAAA;IAE/C,IAAAC,QAAA,KAAa,MAAMnD,QAAU,EAAA;MAE/BqB,IAAA,CAAKmB,KAAKxC,QAAQ,CAAA;MACDyB,gBAAA,CAAAW,GAAA,CAAIa,IAAIjD,QAAQ,CAAA;eACxBA,QAAU,EAAA;MAEdqB,IAAA,CAAAgC,MAAA,CAAOF,QAAU,EAAA,CAAA,EAAGnD,QAAQ,CAAA;MAChByB,gBAAA,CAAAW,GAAA,CAAIa,IAAIjD,QAAQ,CAAA;IAAA,CAC5B,MAAA;MAEAqB,IAAA,CAAAgC,MAAA,CAAOF,UAAU,CAAC,CAAA;MACvB1B,gBAAA,CAAiB6B,OAAOL,EAAE,CAAA;IAC5B;EAAA,CACF;EAEA,OAAO;IAAC1D,WAAA,EAAahC,QAAS,CAAAgC,WAAA;IAAagC;EAAM,CAAA;AACnD;AAEA,SAASW,sBAAAA,CACPP,WACA4B,SACkB,EAAA;EAEZ,MAAAC,MAAA,GAAA,mBAAa9B,GAA6B,EAAA;EACtC6B,SAAA,CAAApB,OAAA,CAASsB,QAAa,IAAA;IAC9B,MAAMC,QAAQF,MAAO,CAAAV,GAAA,CAAIW,QAAS,CAAAZ,UAAU,KAAK,EAAC;IAClDa,KAAA,CAAMlB,KAAKiB,QAAQ,CAAA;IACZD,MAAA,CAAApB,GAAA,CAAIqB,QAAS,CAAAZ,UAAA,EAAYa,KAAK,CAAA;EAAA,CACtC,CAAA;EAGMF,MAAA,CAAArB,OAAA,CAAQ,CAACuB,KAAA,EAAOT,EAAO,KAAA;IAC5B,MAAMjD,WAAW2B,SAAU,CAAAgC,IAAA,CAAM/D,GAAQ,IAAAA,GAAA,CAAIC,QAAQoD,EAAE,CAAA;IACvD,IAAI,CAACjD,QAAU,EAAA;MAGL4D,OAAA,CAAAC,IAAA,CAAK,6CAA6CZ,EAAE,CAAA;MAC5D;IACF;IAIA,IAAIa,gBAAmB,GAAA,KAAA;IACvB,IAAIZ,OAAiC,GAAAlD,QAAA;IAC/B0D,KAAA,CAAAvB,OAAA,CAASsB,QAAa,IAAA;MACPK,gBAAA,GAAAA,gBAAA,IAAoBL,QAAS,CAAAM,WAAA,KAAgB/D,QAAS,CAAAK,IAAA;MACzE,IAAI,CAACyD,gBAAkB,EAAA;QACrB;MACF;MAEA,IAAIL,SAASb,OAAS,EAAA;QACpBM,OAAA,GAAUhD,oBAAqB,CAAAgD,OAAA,EAASO,QAAS,CAAAb,OAAA,CAAQI,KAAK,CAAA;MAChE;IAAA,CACD,CAAA;IAGDrB,SAAA,CAAU0B,OAAO1B,SAAU,CAAAyB,OAAA,CAAQpD,QAAQ,CAAA,EAAG,GAAGkD,OAAO,CAAA;EAAA,CACzD,CAAA;EAEM,OAAAvB,SAAA;AACT;AAEA,SAASL,QAAQK,SAA+C,EAAA;EACxD,MAAAqC,SAAA,GAAA,mBAAgBtC,GAA4B,EAAA;EAExCC,SAAA,CAAAQ,OAAA,CAASvC,GAAQ,IAAA;IACzB,MAAMqE,QAAW,GAAAD,SAAA,CAAUlB,GAAI,CAAA/C,cAAA,CAAeH,GAAG,CAAC,CAAA;IAClD,IAAIA,GAAI,CAAAC,GAAA,CAAIC,UAAW,CAAA,SAAS,CAAG,EAAA;MAEjCkE,SAAA,CAAU5B,IAAIrC,cAAe,CAAAH,GAAG,CAAG,EAAAsE,uBAAA,CAAwBtE,GAAG,CAAC,CAAA;IAAA,CACjE,MAAA,IAAW,CAACqE,QAAU,EAAA;MAEVD,SAAA,CAAA5B,GAAA,CAAIxC,GAAI,CAAAC,GAAA,EAAKD,GAAG,CAAA;IAC5B;EAAA,CACD,CAAA;EAED,OAAOuE,KAAM,CAAAC,IAAA,CAAKJ,SAAU,CAAAK,MAAA,EAAQ,CAAA;AACtC;AAIA,SAASH,wBAAwBtE,GAAqC,EAAA;EACpE,OAAO;IAAC,GAAGA,GAAA;IAAKC,GAAK,EAAAE,cAAA,CAAeH,GAAG;EAAC,CAAA;AAC1C;ACjMgB,SAAA0E,WAAAC,CAAU7G,QAAgB8G,kBAAmD,EAAA;EAC3F,IAAI7C,YAA8B,EAAC;EACnC,MAAM8C,gBAAmB,GAAAC,QAAA,CAAShH,MAAO,CAAAiH,sBAAA,IAA0B,IAAIC,uBAAuB,CAAA;EAC9F,MAAMC,sBAA0C,EAAC;EAE7C,IAAAhH,OAAA;EAEJ,eAAeiH,WAAcA,CAAA,EAAA;IAC3B,IAAI,CAACjH,OAAS,EAAA;MACFA,OAAA,GAAA4C,iBAAA,CACR/C,MAAA,EACC2D,IAAS,IAAA;QACIM,SAAA,GAAAN,IAAA;QACKoD,gBAAA,EAAA;MACnB,CAAA,EACAD,kBAAA,CACF;IACF;IAEA,MAAM3G,OAAQ,CAAA0D,MAAA;EAChB;EAEe,eAAAwD,KAAAA,CAAeC,WAAmBC,MAA8C,EAAA;IAC7F,MAAMH,WAAY,EAAA;IAClB,MAAMI,IAAO,GAAAtG,KAAA,CAAMoG,SAAW,EAAA;MAACC;IAAO,CAAA,CAAA;IAChC,MAAAE,MAAA,GAAS,MAAMC,QAAS,CAAAF,IAAA,EAAa;MAACrH,OAAS,EAAA8D,SAAA;MAAWsD;KAAO,CAAA;IACvE,OAAOE,OAAOrC,GAAI,EAAA;EACpB;EAEA,eAAeuC,YAAYxC,UAAoD,EAAA;IAC7E,MAAMiC,WAAY,EAAA;IAClB,OAAOC,KAAM,CAAAO,IAAA,CAAAC,eAAA,KAAAA,eAAA,GAAAC,sBAAA,0BAAwB;MAACvC,EAAA,EAAIJ;KAAW,CAAA;EACvD;EAEA,eAAejC,aAAa6E,WAA2D,EAAA;IACrF,MAAMX,WAAY,EAAA;IACZ,MAAAY,UAAA,GAAaD,YAAYE,GAAI,CAAC1C,2BAAoBA,EAAA,WAAS,CAAE,CAAA2C,IAAA,CAAK,KAAK,CAAA;IACtE,OAAAb,KAAA,KAAA9G,MAAA,CAAUyH,UAAa,OAAA;EAChC;EAES,SAAAG,SAAAA,CACPb,SACA,EAAAC,MAAA,EACAa,QACc,EAAA;IACV,IAAA,CAACpI,OAAOF,MAAQ,EAAA;MACZ,MAAA,IAAIuB,MAAM,iDAAiD,CAAA;IACnE;IAKA,MAAMgH,YAAe,GAAA;MAAChB,KAAO,EAAAC,SAAA;MAAWC;MAAQa;IAAQ,CAAA;IACxDjB,mBAAA,CAAoBrC,KAAKuD,YAAY,CAAA;IAErC,IAAIC,YAAe,GAAA,KAAA;IACnB,MAAMzG,cAAcA,CAAA,KAAM;MACxB,IAAIyG,YAAc,EAAA;QAChB,OAAOxG,QAAQC,OAAQ,EAAA;MACzB;MAEeuG,YAAA,GAAA,IAAA;MACfnB,mBAAA,CAAoBxB,MAAO,CAAAwB,mBAAA,CAAoBzB,OAAQ,CAAA2C,YAAY,GAAG,CAAC,CAAA;MACvE,OAAOvG,QAAQC,OAAQ,EAAA;IAAA,CACzB;IAEAwG,wBAAA,CAAyBF,YAAY,CAAA;IACrC,OAAO;MAACxG;IAAW,CAAA;EACrB;EAEA,SAAS0G,yBAAyBF,YAAgC,EAAA;IACzD,OAAAhB,KAAA,CAAMgB,aAAahB,KAAO,EAAAgB,YAAA,CAAad,MAAM,CACjD,CAAAzD,IAAA,CAAM0E,GAAQ,IAAA;MACb,IAAI,oBAAoBH,YAAgB,IAAAI,SAAA,CAAUJ,YAAa,CAAAK,cAAA,EAAgBF,GAAG,CAAG,EAAA;QACnF;MACF;MAEAH,YAAA,CAAaK,cAAiB,GAAAF,GAAA;MACjBH,YAAA,CAAAD,QAAA,CAAS,QAAWI,GAAG,CAAA;IAAA,CACrC,CAAA,CACAG,KAAM,CAACxH,GAAQ,IAAA;MACdkH,YAAA,CAAaD,SAASjH,GAAG,CAAA;IAAA,CAC1B,CAAA;EACL;EAEA,SAAS+F,uBAA0BA,CAAA,EAAA;IACjCC,mBAAA,CAAoB1C,QAAQ8D,wBAAwB,CAAA;EACtD;EAEA,SAASxH,KAAQA,CAAA,EAAA;IACfgG,gBAAA,CAAiB6B,MAAO,EAAA;IACxB,OAAOzI,OAAU,GAAAA,OAAA,CAAQ0B,WAAY,EAAA,GAAIC,QAAQC,OAAQ,EAAA;EAC3D;EAEA,OAAO;IAACsF,KAAA;IAAOM,WAAa;IAAAzE,YAAA;IAAciF;IAAWpH;EAAK,CAAA;AAC5D;ACpGO,SAAS8H,cAAcpB,MAAyD,EAAA;EACrF,IAAI,CAACA,MAAQ,EAAA;IACJ,OAAA,KAAA;EACT;EAEI,IAAA,EAAE,WAAWA,MAAW,CAAA,IAAA,OAAOA,OAAOrG,KAAU,KAAA,QAAA,IAAYqG,MAAO,CAAArG,KAAA,KAAU,IAAM,EAAA;IAC9E,OAAA,KAAA;EACT;EAGE,OAAA,aAAA,IAAiBqG,OAAOrG,KACxB,IAAA,OAAQqG,OAAuBrG,KAAM,CAAA0H,WAAA,KAAgB,QACrD,IAAA,EAAE,KAAS,IAAArB,MAAA,CAAA;AAEf;AAEO,SAASsB,SAASC,IAAwB,EAAA;EAC/C,IAAI,OAAOA,IAAS,KAAA,QAAA,IAAY,OAAW,IAAAA,IAAA,IAAQ,aAAaA,IAAM,EAAA;IAC7D,OAAAA,IAAA,CAAK1H,WAAW0H,IAAK,CAAA5H,KAAA;EAC9B;EAEO,OAAA,iBAAA;AACT;AAEO,SAAS6H,mBAAmB/G,GAA8B,EAAA;EAC/D,OAAO,CAACA,GAAA,CAAIC,GAAI,CAAAC,UAAA,CAAW,IAAI,CAAA;AACjC;ACvBa,MAAAc,YAAA,GAAmD,SAASA,aAAagG,CAAAC,KAAA,EAYxD;EAAA,IAZwD;IACpFjJ,SAAA;IACAC,OAAA;IACAC,KAAA;IACAiD,aAAA;IACAC,eAAe;EACjB,CAM8B,GAAA6F,KAAA;EACtB,MAAAC,OAAA,cAAA7I,MAAA,CAAqBL,SAA0C,oCAAAK,MAAA,CAAAJ,OAAA,CAAA;EACrE,MAAMoH,MACJ,GAAAjE,YAAA,CAAa+F,MAAS,GAAA,CAAA,GAAI,IAAIC,eAAA,CAAgB;IAACC,KAAA,EAAOjG,YAAc,IAAA,IAAA,GAAA,KAAA,CAAA,GAAAA,YAAA,CAAA4E,IAAA,CAAK,GAAI;EAAA,CAAC,CAAI,GAAA,EAAA;EAC9E,MAAA1H,GAAA,MAAAD,MAAA,CAAS6I,OAAW,OAAA7I,MAAA,CAAAgH,MAAA,CAAA;EAC1B,MAAMlH,UAAUD,KAAQ,GAAA;IAACE,aAAe,YAAAC,MAAA,CAAUH;GAAW,GAAA,KAAA,CAAA;EAE7D,OAAO,IAAI0B,OAAA,CAAQ,CAACC,OAAA,EAASsC,MAAW,KAAA;IACtCe,GAAA,CAAI;MAAC5E,GAAK;MAAAH;IAAU,CAAA,EAAA,CAACc,KAAKqI,QAAa,KAAA;MACrC,IAAIrI,GAAK,EAAA;QACPkD,MAAA,CAAOlD,GAAG,CAAA;QACV;MACF;MAEAqI,QAAA,CAASC,YAAY,MAAM,CAAA;MAE3B,MAAMC,SAAmB,EAAC;MACtB,IAAAF,QAAA,CAASjI,eAAe,GAAK,EAAA;QAE5BiI,QAAA,CAAAG,EAAA,CAAG,MAAQ,EAACC,KAAkB,IAAAF,MAAA,CAAO5E,IAAK,CAAA8E,KAAK,CAAC,CAAA,CAChDD,EAAG,CAAA,KAAA,EAAO,MAAM;UACT,MAAAX,IAAA,GAAO/H,KAAKC,KAAM,CAAA2I,MAAA,CAAOtJ,OAAOmJ,MAAM,CAAA,CAAEI,QAAS,CAAA,MAAM,CAAC,CAAA;UAC9DzF,MAAA,CAAO,IAAIhD,KAAM,6BAAAd,MAAA,CAA4BwI,QAAS,CAAAC,IAAI,GAAI,CAAA;QAAA,CAC/D,CAAA;QACH;MACF;MAEA,MAAM/E,YAA8B,EAAC;MAElCuF,QAAA,CAAAO,IAAA,CAAKC,MAAM/I,IAAK,CAAAC,KAAK,CAAC,CACtB,CAAAyI,EAAA,CAAG,MAAQ,EAACzH,GAAsB,IAAA;QAC7B,IAAA2G,aAAA,CAAc3G,GAAG,CAAG,EAAA;UACtBmC,MAAA,CAAO,IAAIhD,KAAA,6BAAAd,MAAA,CAAkC2B,GAAA,CAAId,OAAQ,CAAA;UACzD;QACF;QAEI,IAAAc,GAAA,IAAO+G,kBAAmB,CAAA/G,GAAG,CAAG,EAAA;UAClC+B,SAAA,CAAUa,KAAK5C,GAAG,CAAA;QACpB;QAEI,IAAAmB,aAAA,IAAiBY,SAAU,CAAAoF,MAAA,GAAShG,aAAe,EAAA;UACrDgB,MAAA,CACE,IAAIhD,KAAM,8CAAAd,MAAA,CAA6C8C,aAAyB,gBAAA,CAClF;UACAmG,QAAA,CAASS,OAAQ,EAAA;QACnB;MAAA,CACD,CACA,CAAAN,EAAA,CAAG,OAAO,MAAM5H,OAAA,CAAQkC,SAAS,CAAC,CAAA;IAAA,CACtC,CAAA;EAAA,CACF,CAAA;AACH,CAAA;ACpEO,SAASiG,gBAAyBA,CAAA,EAAA;EACvC,MAAM,CAACC,KAAK,CAAI,GAAAC,OAAA,CAAQC,QAAQC,OAAQ,CAAA,IAAA,EAAM,EAAE,CAAA,CAAEN,KAAM,CAAA,GAAA,EAAK,CAAC,CAAA,CAAE/B,IAAIsC,MAAM,CAAA;EAC1E,IAAIJ,QAAQ,EAAI,EAAA;IACR,MAAA,IAAI9I,MAAM,uCAAuC,CAAA;EACzD;AACF;ACKO,SAASuF,UAAU5G,MAA2B,EAAA;EAVrD,IAAAwK,EAAA;EAWmBN,gBAAA,EAAA;EAEjB,OAAOO,YAAazK,MAAQ,EAAA;IAC1BR,WAAA,EAAA,CAAagL,EAAO,GAAAxK,MAAA,CAAAR,WAAA,KAAP,IAAsB,GAAAgL,EAAA,GAAAE,mBAAA;IACnCxH;EAAA,CACD,CAAA;AACH;"}